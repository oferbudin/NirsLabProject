{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4dcfb50",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc8b9ca7",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-11-07T14:08:01.335732900Z",
     "start_time": "2023-11-07T14:07:52.101207200Z"
    }
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import scipy.stats as sp_stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from NirsLabProject.config.consts import *\n",
    "from NirsLabProject.config.subject import Subject\n",
    "\n",
    "from NirsLabProject.utils import *\n",
    "from NirsLabProject.utils.sleeping_utils import *\n",
    "\n",
    "sleep_cycle = False\n",
    "subject = Subject('p487', True)\n",
    "\n",
    "raw = mne.io.read_raw_fif(subject.paths.subject_resampled_fif_path)\n",
    "# raw.plot()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c858b2e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T14:16:28.843153100Z",
     "start_time": "2023-11-07T14:08:32.853903600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43344\n",
      "(72, 3)\n",
      "LA\n",
      "LA\n",
      "LA\n",
      "LA\n",
      "LA\n",
      "LA\n",
      "LA\n",
      "0\n",
      "LAH\n",
      "LAH\n",
      "LAH\n",
      "LAH\n",
      "LAH\n",
      "LAH\n",
      "LAH\n",
      "7\n",
      "LEC\n",
      "LEC\n",
      "LEC\n",
      "LEC\n",
      "LEC\n",
      "LEC\n",
      "LEC\n",
      "14\n",
      "LOF\n",
      "LOF\n",
      "LOF\n",
      "LOF\n",
      "LOF\n",
      "LOF\n",
      "LOF\n",
      "LOF\n",
      "21\n",
      "LPHG\n",
      "LPHG\n",
      "LPHG\n",
      "LPHG\n",
      "LPHG\n",
      "LPHG\n",
      "LPHG\n",
      "29\n",
      "LSTG\n",
      "LSTG\n",
      "LSTG\n",
      "LSTG\n",
      "LSTG\n",
      "LSTG\n",
      "LSTG\n",
      "36\n",
      "RA\n",
      "RA\n",
      "RA\n",
      "RA\n",
      "RA\n",
      "RA\n",
      "RA\n",
      "RA\n",
      "43\n",
      "RAH\n",
      "RAH\n",
      "RAH\n",
      "RAH\n",
      "RAH\n",
      "RAH\n",
      "RAH\n",
      "51\n",
      "REC\n",
      "REC\n",
      "REC\n",
      "REC\n",
      "REC\n",
      "REC\n",
      "REC\n",
      "58\n",
      "ROF\n",
      "ROF\n",
      "ROF\n",
      "ROF\n",
      "ROF\n",
      "ROF\n",
      "ROF\n",
      "65\n",
      "6666666\n"
     ]
    }
   ],
   "source": [
    "# spikes = np.load(subject.paths.subject_spikes_path)\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def find_high_spikes_channels(spikes: np.ndarray, raw: mne.io.Raw, threshold: float = 5):\n",
    "    high_spikes_channels = {}\n",
    "    spikes_per_minute = np.zeros_like(raw.ch_names, dtype=float)\n",
    "    for i, channel_name in enumerate(spikes):\n",
    "        channel_raw = raw.copy().pick_channels([channel_name])\n",
    "        channel_spikes = spikes[channel_name]\n",
    "        number_of_spikes = channel_spikes.shape[0]\n",
    "        channel_total_time_in_minutes = (channel_raw.tmax - channel_raw.tmin) / (60)\n",
    "        spikes_per_minute[i] = number_of_spikes / channel_total_time_in_minutes\n",
    "\n",
    "    zscores = sp_stats.zscore(spikes_per_minute)\n",
    "    print(zscores)\n",
    "    print(spikes_per_minute)\n",
    "    for i, channel_name in enumerate(spikes):\n",
    "        if zscores[i] > 1:\n",
    "            print(channel_name)\n",
    "            \n",
    "    return high_spikes_channels\n",
    "            \n",
    "\n",
    "def find_bad_channels(spikes: np.ndarray, raw: mne.io.Raw):\n",
    "    n_time_windows = int(raw.tmax-raw.tmin)\n",
    "    channel_names = list(raw.ch_names)\n",
    "    bad_channels = np.zeros((len(channel_names), 3))\n",
    "    print(bad_channels.shape)\n",
    "    \n",
    "    area_norms = {}\n",
    "    area_norms_stds = {}\n",
    "    area_norms_skew = {}\n",
    "    area_norms_kurtosis = {}\n",
    "\n",
    "    total_channel_index = 0\n",
    "    for i, channel_name in enumerate(channel_names):\n",
    "        channel_area = channel_name[:-1]\n",
    "        print(channel_area)\n",
    "        if channel_area not in area_norms:\n",
    "            area_norms[channel_area] = []\n",
    "            area_norms_stds[channel_area] = []\n",
    "            area_norms_skew[channel_area] = []\n",
    "            area_norms_kurtosis[channel_area] = []\n",
    "            \n",
    "        channel_index = channel_name[-1]\n",
    "        channel_raw = raw.copy().pick_channels([channel_name])\n",
    "        channel_data = channel_raw.get_data()[0]\n",
    "        norms = np.zeros(n_time_windows)\n",
    "        for window_index in range(n_time_windows):\n",
    "            norms[window_index] = np.sqrt(np.nansum(channel_data[(window_index-1)*SR:window_index*SR]**2))\n",
    "        area_norms[channel_area].append(norms)\n",
    "        area_norms_stds[channel_area].append(np.std(norms))\n",
    "        area_norms_skew[channel_area].append(skew(norms))\n",
    "        area_norms_kurtosis[channel_area].append(kurtosis(norms))\n",
    "        \n",
    "        if i == len(channel_names)-1 or channel_names[i+1][-1] < channel_index:\n",
    "            print(total_channel_index)\n",
    "            for channel_area, channels in area_norms.items():\n",
    "                area_norms_stds_median = np.median(area_norms_stds[channel_area])\n",
    "                area_norms_skew_median = np.median(area_norms_skew[channel_area])\n",
    "                area_norms_kurtosis_median = np.median(area_norms_kurtosis[channel_area])\n",
    "\n",
    "\n",
    "                for i, _ in enumerate(channels):\n",
    "                    if area_norms_stds[channel_area][i] > area_norms_stds_median*4:\n",
    "                        bad_channels[total_channel_index][0] = 2\n",
    "                    elif area_norms_stds[channel_area][i] > area_norms_stds_median*2:\n",
    "                          bad_channels[total_channel_index][0] = 1.5\n",
    "                    elif area_norms_stds[channel_area][i] > area_norms_stds_median*1.5:\n",
    "                        bad_channels[total_channel_index][0] = 1\n",
    "\n",
    "                    if area_norms_skew[channel_area][i] > area_norms_skew_median*4:\n",
    "                        bad_channels[total_channel_index][1] = 2\n",
    "                    elif area_norms_skew[channel_area][i] > area_norms_skew_median*2:\n",
    "                        bad_channels[total_channel_index][1] = 1\n",
    "\n",
    "                    if area_norms_kurtosis[channel_area][i] > area_norms_kurtosis_median*4:\n",
    "                        bad_channels[total_channel_index][2] = 2\n",
    "                    elif area_norms_kurtosis[channel_area][i] > area_norms_kurtosis_median*2:\n",
    "                        bad_channels[total_channel_index][2] = 1\n",
    "                                            \n",
    "                    total_channel_index += 1\n",
    "            area_norms = {}\n",
    "        \n",
    "    return bad_channels\n",
    "    \n",
    "# channels_names_list = list(spikes.keys())\n",
    "print(43344)\n",
    "bd = find_bad_channels([], raw.copy())\n",
    "print(6666666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86f2e7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROF3 [1.5 1.  2. ]\n",
      "RAC1 [1.5 0.  0. ]\n",
      "LA7 [2. 1. 2.]\n",
      "LOF7 [0. 0. 2.]\n",
      "LAC1 [2. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "for i, line in enumerate(bd):\n",
    "    if np.sum(bd[i]) > 1:\n",
    "        print(raw.ch_names[i], bd[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d22e84b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '~/output.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 14\u001B[0m\n\u001B[1;32m     11\u001B[0m         group \u001B[38;5;241m=\u001B[39m [arr[i, :]]\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcsv\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m~/output.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mw\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m csvfile:\n\u001B[1;32m     15\u001B[0m     writer \u001B[38;5;241m=\u001B[39m csv\u001B[38;5;241m.\u001B[39mwriter(csvfile)\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m group \u001B[38;5;129;01min\u001B[39;00m groups:\n",
      "File \u001B[0;32m~/miniforge3/envs/mne/lib/python3.9/site-packages/IPython/core/interactiveshell.py:282\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    275\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    276\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    277\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    278\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    279\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    280\u001B[0m     )\n\u001B[0;32m--> 282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '~/output.csv'"
     ]
    }
   ],
   "source": [
    "window_width = 100  # in milliseconds\n",
    "\n",
    "# Group the timestamps based on the window_width\n",
    "groups = []\n",
    "group = [arr[0]]\n",
    "for i in range(1, arr.shape[0]):\n",
    "    if group[0][0] + window_width > arr[i][0]:\n",
    "        group.append(arr[i])\n",
    "    else:\n",
    "        groups.append(group)\n",
    "        group = [arr[i, :]]\n",
    "\n",
    "import csv\n",
    "with open('output.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for group in groups:\n",
    "        hemisphers = set()\n",
    "        stractures = set()\n",
    "        size = len(group)\n",
    "        fist_timestamp = group[0][0]\n",
    "        last_timestamp = group[-1][0]\n",
    "        first = sorted([spike for spike in group if spike[0] == fist_timestamp], key=lambda x: (x[1], x[2]))[-1]\n",
    "        first = index_to_channel[first[1]]\n",
    "        timing_diffrence = last_timestamp - fist_timestamp\n",
    "        for record in group:\n",
    "            channel = index_to_channel[record[1]]\n",
    "            hemisphers.add(channel[0])\n",
    "            stractures.add(channel[:-1])\n",
    "        if size > 2:\n",
    "            row = [size, first, (hemisphers), (stractures), timing_diffrence]\n",
    "            writer.writerow(row)\n",
    "#             print(f'Grouop size {size} | Focal: {first} | Hemisphers: {hemisphers} | Stractures: {stractures} | Time Difrences: {timing_diffrence}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ada82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict\n",
    "from NirsLabProject import spikes_detection\n",
    "from NirsLabProject.pipeline import channel_processing\n",
    "\n",
    "spikes = spikes_detection.detect_spikes_of_subject(subject, raw)\n",
    "channel_names = spikes.keys()\n",
    "channels_spikes = Parallel(n_jobs=os.cpu_count(), backend='multiprocessing')(\n",
    "        delayed(channel_processing)(subject, raw, dict(spikes), channel_name, i) for i, channel_name in enumerate(channel_names)\n",
    "    )\n",
    "channels_spikes_features = {channel_name: channel_spikes for channel_name, channel_spikes in zip(channel_names, channels_spikes)}\n",
    "channel_spikes = {channel_name: channel_spikes[:,0] / SR for channel_name, channel_spikes in channels_spikes_features.items()}\n",
    "\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f3145958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.00000000e+00 2.20000000e+01 4.91686426e+00 8.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [1.80000000e+01 8.00000000e+00 4.48488629e+00 1.00000000e+01\n",
      "  0.00000000e+00]\n",
      " [2.00000000e+01 5.00000000e+00 4.43637427e+00 8.00000000e+00\n",
      "  0.00000000e+00]\n",
      " ...\n",
      " [2.95827000e+07 5.60000000e+01 1.46590371e+01 7.00000000e+00\n",
      "  2.90480000e+04]\n",
      " [2.95827020e+07 5.00000000e+00 2.20556207e+01 6.00000000e+00\n",
      "  2.90480000e+04]\n",
      " [2.95827020e+07 2.20000000e+01 2.34305851e+01 6.00000000e+00\n",
      "  2.90480000e+04]]\n"
     ]
    }
   ],
   "source": [
    "from NirsLabProject.group_spikes import MinHeap\n",
    "\n",
    "class Group:\n",
    "    def __init__(self, group, group_index, index_to_channel):\n",
    "        self._group = group\n",
    "        self.index = group_index\n",
    "        self.size = len(group)\n",
    "        self.fist_event_timestamp = group[0][TIMESTAMP_INDEX]\n",
    "        self.last_event_timestamp = group[-1][TIMESTAMP_INDEX]\n",
    "        self.group_event_duration = self.last_event_timestamp - self.fist_event_timestamp\n",
    "        self.focal_channnel_index = sorted(\n",
    "            [spike for spike in group if spike[0] == self.fist_event_timestamp],\n",
    "            key=lambda x: (x[1], x[2])\n",
    "        )[-1][1]\n",
    "        self.focal_channnel_name = index_to_channel[self.focal_channnel_index]\n",
    "\n",
    "        self.hemisphers = set()\n",
    "        self.stractures = set()\n",
    "\n",
    "        for record in group:\n",
    "            channel = index_to_channel[record[1]]\n",
    "            self.hemisphers.add(channel[0])\n",
    "            self.stractures.add(channel[:-1])\n",
    "            \n",
    "        def __str__(self):\n",
    "            return f'Grouop size {size} | Focal: {first} | Hemisphers: {hemisphers} | Stractures: {stractures} | Time Difrences: {timing_diffrence}'\n",
    "\n",
    "\n",
    "def group_spikes(channels_spikes: Dict[str, np.ndarray]):\n",
    "    index_to_channel = {}\n",
    "    for i, channel_name in enumerate(channels_spikes.keys()):\n",
    "        index_to_channel[i] = channel_name\n",
    "    \n",
    "    # Merge all the spikes into one sorted array\n",
    "    all_spikes = [spikes for spikes in channels_spikes.values() if spikes.shape[0] > 0]\n",
    "    all_spikes_flat = MinHeap.mergeKSortedArrays(all_spikes, len(all_spikes))\n",
    "            \n",
    "    # Group the timestamps based on the window_width\n",
    "    groups_list = []\n",
    "    group_index_to_group = {}\n",
    "    group = [all_spikes_flat[0]]\n",
    "    for i in range(1, all_spikes_flat.shape[0]):\n",
    "        if group[0][0] + SPIKES_GROUPING_WINDOW_SIZE > all_spikes_flat[i][0]:\n",
    "            group.append(all_spikes_flat[i])\n",
    "        else:\n",
    "            groups_list.append(group)\n",
    "            group = [all_spikes_flat[i, :]]\n",
    "    groups_list.append(group)\n",
    "    \n",
    "    spike_index = 0\n",
    "    all_spikes_group_indexes = np.zeros(all_spikes_flat.shape[0], dtype=int)\n",
    "    for group_index, group in enumerate(groups_list):\n",
    "        group = Group(group, group_index, index_to_channel)\n",
    "        group_index_to_group[group_index] = group\n",
    "        for i in range(group.size):\n",
    "            all_spikes_group_indexes[spike_index] = group.index\n",
    "            spike_index +=1\n",
    "        \n",
    "    all_spikes_group_indexes = all_spikes_group_indexes.reshape((-1, 1))\n",
    "    all_spikes_flat = np.concatenate((all_spikes_flat, all_spikes_group_indexes), axis=1)\n",
    "    \n",
    "    return group_index_to_group, all_spikes_flat\n",
    "\n",
    "\n",
    "    \n",
    "groups, flat_features = group_spikes(channels_spikes_features)\n",
    "\n",
    "# print(flat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c5acb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12024024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
